{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* NOTE: Some of the sentiments of each organization may be skewed because of the account posting a video or image with no text description\n",
    "* The CBS' twitter account has the highest overall positive sentiment, as its compound score is well above the positive sentiment threshold of 0.05 at around 0.35.\n",
    "* The New York Times tweets have sentiments that mainly vary from positive to neutral with around 20 tweets that are more negative\n",
    "* Fox News' twitter account sentiments vary as it may be negative one day and back to neutral another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dependences\n",
    "import pandas as pd\n",
    "import random\n",
    "import requests\n",
    "import tweepy\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from config import consumer_key, consumer_secret, access_token, access_token_secret\n",
    "from pprint import pprint\n",
    "# Setting authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())\n",
    "# Import and Initialize Sentiment Analyzer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting target users for VADER analysis\n",
    "target_users = [\"@BBC\", \"@CBS\", \"@CNN\", \"@FoxNews\",\"@nytimes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting list to store data for dataframe\n",
    "compound_list = []\n",
    "positive_list = []\n",
    "neutral_list = []\n",
    "negative_list = []\n",
    "unique_id = [] \n",
    "user_name= []\n",
    "tweet_created_at = []\n",
    "tweets_ago = []\n",
    "tweet_content = [] \n",
    "# Looping through each target user in the list \n",
    "for user in target_users:    \n",
    "    public_tweets = api.user_timeline(user,count=100, result_type=\"recent\")\n",
    "    counter = 0\n",
    "    # Looping through each tweet \n",
    "    for tweet in public_tweets:\n",
    "        # Appending the user to the user name list\n",
    "        user_name.append(tweet[\"user\"][\"name\"])\n",
    "        # Appending to the unique_id list by each unique tweet ID\n",
    "        tweet_id = tweet[\"id_str\"]\n",
    "        unique_id.append(tweet_id)\n",
    "        #VADER analysis and appending to their resepctive lists\n",
    "        results = analyzer.polarity_scores(tweet[\"text\"])\n",
    "        compound = results[\"compound\"]\n",
    "        compound_list.append(compound)\n",
    "        pos = results[\"pos\"]\n",
    "        positive_list.append(pos)\n",
    "        neu = results[\"neu\"]\n",
    "        neutral_list.append(neu)\n",
    "        neg = results[\"neg\"]\n",
    "        negative_list.append(neg)\n",
    "        tweet_text = tweet[\"text\"]\n",
    "        tweet_tweet = re.search(r\"([\\w\\.'\\?\\s@:!/#]+)\", tweet_text)\n",
    "        tweet_no_emoji = tweet_tweet.group(1)\n",
    "        # Appending the tweet text to an empty list \n",
    "        tweet_content.append(tweet_no_emoji)\n",
    "        # Appending to the tweet_created_at list to find the date when the tweet was made \n",
    "        creation_date = tweet[\"created_at\"]\n",
    "        tweet_created_at.append(creation_date)\n",
    "        if tweet_id not in unique_id:\n",
    "            unique_id.append(tweet_id)     \n",
    "        # Putting everything into a dictionary \n",
    "        sentiments = ({\"Tweet ID\": unique_id,\n",
    "                       \"User\": user_name,\n",
    "                       \"Tweet\": tweet_content,\n",
    "                      \"Compound Score\": compound_list,\n",
    "                       \"Positive Score\": positive_list,\n",
    "                       \"Neutral Score\": neutral_list,\n",
    "                       \"Negative Score\": negative_list,\n",
    "                       \"Date\": tweet_created_at,\n",
    "                       \"Tweets Ago\": tweets_ago})\n",
    "        # Counting how many tweets ago and accounting to the list \n",
    "        counter += 1        \n",
    "        tweets_ago.append(counter)\n",
    "# Creating a data frame to be used for graphs\n",
    "sentiment_df = pd.DataFrame(sentiments)\n",
    "sentiment_df = sentiment_df[[\"Tweet ID\", \"User\",\"Tweet\",\"Compound Score\",\"Positive Score\",\"Neutral Score\",\"Negative Score\",\"Tweets Ago\",\"Date\"]]\n",
    "print(len(sentiment_df))\n",
    "sentiment_df\n",
    "sentiment_df.to_csv(\"news_sentiment.csv\",encoding=\"UTF-8\",index=True)\n",
    "print(sentiment_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Tweets Sentiment Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating each tweet into their respective users\n",
    "bbc = sentiment_df[sentiment_df[\"User\"] == \"BBC\"]\n",
    "cbs = sentiment_df[sentiment_df[\"User\"] == \"CBS\"]\n",
    "cnn = sentiment_df[sentiment_df[\"User\"] == \"CNN\"]\n",
    "fox = sentiment_df[sentiment_df[\"User\"] == \"Fox News\"]\n",
    "nytimes = sentiment_df[sentiment_df[\"User\"] == \"The New York Times\"]\n",
    "# Setting plots for each user \n",
    "plt.scatter(bbc[\"Tweets Ago\"], bbc[\"Compound Score\"],c=\"lightblue\",alpha=0.75,edgecolor=\"black\",label=\"BBC\")\n",
    "plt.scatter(cbs[\"Tweets Ago\"], cbs[\"Compound Score\"],c=\"green\",alpha=0.75,edgecolor=\"black\",label=\"CBS\")\n",
    "plt.scatter(cnn[\"Tweets Ago\"], cnn[\"Compound Score\"],c=\"red\",alpha=0.75,edgecolor=\"black\",label=\"CNN\")\n",
    "plt.scatter(fox[\"Tweets Ago\"], fox[\"Compound Score\"],c=\"blue\",alpha=0.75,edgecolor=\"black\",label=\"Fox News\")\n",
    "plt.scatter(nytimes[\"Tweets Ago\"], nytimes[\"Compound Score\"],c=\"yellow\",alpha=0.75,edgecolor=\"black\",label=\"The New York Times\")\n",
    "cur_date = datetime.now()\n",
    "cur_date = cur_date.strftime(\"%Y-%m-%d\")\n",
    "plt.title(f\"Sentiment Analysis of Media Tweets {cur_date}\")\n",
    "plt.xlabel(\"Tweets Ago\")\n",
    "plt.ylabel(\"Tweet Polarity\")\n",
    "plt.xlim(105,-5)\n",
    "plt.ylim(-1.1,1.1)\n",
    "legend = plt.legend(frameon=False,labelspacing=0.2,loc=\"right\",bbox_to_anchor=(1.5, 0.5))\n",
    "legend.set_title(\"Media Sources\")\n",
    "legend.legendHandles[0]\n",
    "legend.legendHandles[1]\n",
    "legend.legendHandles[2]\n",
    "legend.legendHandles[3]\n",
    "legend.legendHandles[4]\n",
    "plt.grid()\n",
    "plt.savefig(\"plots/sentiment_scatter_plot.png\",dpi=\"figure\",bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall Media Sentiment Based on Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alt\n",
    "# Separating each tweet into their respective users\n",
    "bbc = sentiment_df[sentiment_df[\"User\"] == \"BBC\"]\n",
    "cbs = sentiment_df[sentiment_df[\"User\"] == \"CBS\"]\n",
    "cnn = sentiment_df[sentiment_df[\"User\"] == \"CNN\"]\n",
    "fox = sentiment_df[sentiment_df[\"User\"] == \"Fox News\"]\n",
    "nytimes = sentiment_df[sentiment_df[\"User\"] == \"The New York Times\"]\n",
    "# Finding the average sentiment of each user's tweets\n",
    "bbc_avg = bbc[\"Compound Score\"].mean()\n",
    "cbs_avg = cbs[\"Compound Score\"].mean()\n",
    "cnn_avg = cnn[\"Compound Score\"].mean()\n",
    "fox_avg = fox[\"Compound Score\"].mean()\n",
    "nytimes_avg = nytimes[\"Compound Score\"].mean()\n",
    "# Setting plots for each user \n",
    "plt.bar(bbc[\"User\"], bbc_avg,width=0.95,color=\"lightblue\",alpha=0.75,edgecolor=\"black\",label=\"BBC\")\n",
    "plt.bar(cbs[\"User\"], cbs_avg,width=0.95,color=\"green\",alpha=0.75,edgecolor=\"black\",label=\"CBS\")\n",
    "plt.bar(cnn[\"User\"], cnn_avg,width=0.95,color=\"red\",alpha=0.75,edgecolor=\"black\",label=\"CNN\")\n",
    "plt.bar(fox[\"User\"], fox_avg,width=0.95,color=\"blue\",alpha=0.75,edgecolor=\"black\",label=\"Fox News\")\n",
    "plt.bar(nytimes[\"User\"], nytimes_avg,width=0.95,color=\"yellow\",alpha=0.75,edgecolor=\"black\",label=\"The New York Times\")\n",
    "plt.ylim(-0.1,0.4)\n",
    "plt.title(f\"Overall Media Sentiment based on Twitter {cur_date}\")\n",
    "plt.xlabel(\"Twitter User\")\n",
    "plt.ylabel(\"Tweet Polarity\")\n",
    "plt.savefig(\"plots/overall_media_sentiment.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
